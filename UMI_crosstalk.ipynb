{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nranu/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp_sparse\n",
    "import tables\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from __future__ import division\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Read10x(filepath):   \n",
    "    with tables.open_file(filepath, 'r') as f:\n",
    "        try:\n",
    "            group = f.get_node(f.root)\n",
    "        except tables.NoSuchNodeError:\n",
    "            print \"That genome does not exist in this file.\"\n",
    "        gene_ids = getattr(group, 'gene_ids').read()\n",
    "        gene_names = getattr(group, 'gene_names').read()\n",
    "        gene = getattr(group, 'gene').read()\n",
    "        umi_corrected_reads=getattr(group, 'umi_corrected_reads').read()\n",
    "        nonconf_mapped_reads=getattr(group, 'nonconf_mapped_reads').read()\n",
    "        conf_mapped_uniq_read_pos=getattr(group, 'conf_mapped_uniq_read_pos').read()\n",
    "        unmapped_reads=getattr(group, 'unmapped_reads').read()\n",
    "        barcodes = getattr(group, 'barcode').read()\n",
    "        reads = getattr(group, 'reads').read()\n",
    "        umi = getattr(group, 'umi').read()\n",
    "\n",
    "        TABLE=pd.DataFrame()\n",
    "        TABLE['bc']=barcodes\n",
    "        TABLE['umi']=umi\n",
    "        #TABLE['bcumi']=zip(barcodes,umi)\n",
    "        TABLE['gene']=gene\n",
    "        TABLE['unique']=[1]*len(TABLE)\n",
    "        TABLE['map_logical']=conf_mapped_uniq_read_pos>0\n",
    "        TABLE['read_counts']=reads+nonconf_mapped_reads+unmapped_reads\n",
    "        return TABLE\n",
    "def setenv(newDict):\n",
    "    DNA={}\n",
    "    DNA['A']='00'\n",
    "    DNA['C']='01'\n",
    "    DNA['G']='10'\n",
    "    DNA['T']='11'\n",
    "\n",
    "    BC_DNA2={}\n",
    "    for i in newDict.iterkeys(): \n",
    "        string=newDict[i]\n",
    "        for j in DNA.iterkeys():\n",
    "            string=string.replace(j,DNA[j])\n",
    "        BC_DNA2[i]=int(string,2)\n",
    "    return BC_DNA2\n",
    "np.random.seed(0)\n",
    "\n",
    "GeneBCMatrix = collections.namedtuple('GeneBCMatrix', ['gene_ids', 'gene_names', 'barcodes', 'matrix'])\n",
    "def get_matrix_from_h5(filename, genome):\n",
    "    with tables.open_file(filename, 'r') as f:\n",
    "        try:\n",
    "            dsets = {}\n",
    "            for node in f.walk_nodes('/' + genome, 'Array'):\n",
    "                dsets[node.name] = node.read()\n",
    "            matrix = sp_sparse.csc_matrix((dsets['data'], dsets['indices'], dsets['indptr']), shape=dsets['shape'])\n",
    "            return GeneBCMatrix(dsets['genes'], dsets['gene_names'], dsets['barcodes'], matrix)\n",
    "        except tables.NoSuchNodeError:\n",
    "            raise Exception(\"Genome %s does not exist in this file.\" % genome)\n",
    "        except KeyError:\n",
    "            raise Exception(\"File is missing one or more required datasets.\")\n",
    "def get_gene(BC,df_1):\n",
    "    Total=df_1.gene[df_1.bc==BC].value_counts().to_frame()\n",
    "    Total.columns=['Counts']\n",
    "    genes1=np.zeros(32739)\n",
    "    for index,rows in Total.iterrows():\n",
    "        genes1[index]=rows['Counts']\n",
    "    return genes1[:-1]\n",
    "\n",
    "def get_sample(Tot,reads,temp_sample1_1,barcode):    \n",
    "    if reads[barcode]<Tot[Tot.bc==barcode].Total_reads.sum():\n",
    "        a=reads[barcode]\n",
    "        down=True\n",
    "    elif reads[barcode]>Tot[Tot.bc==barcode].Total_reads.sum():\n",
    "         down=False\n",
    "    if item==17:#PH_23,4\n",
    "        down=False\n",
    "    temp_3=temp_sample1_1[temp_sample1_1.Total_reads>2]\n",
    "    \n",
    "\n",
    "    if down==True:\n",
    "        temp_sample3=temp_3.sample(a)\n",
    "    elif down==False:\n",
    "        temp_sample3=temp_3.copy()\n",
    "\n",
    "\n",
    "    temp_sample3=temp_sample3.drop_duplicates()\n",
    "    return temp_sample3\n",
    "def Expanded_dataframe(tot3):\n",
    "    #converts UMI table to reads table for sampling\n",
    "    tot3=tot3.reset_index()\n",
    "    temp_tot=defaultdict()\n",
    "    counter=0\n",
    "    for item in tot3.index:\n",
    "        counter1=0\n",
    "        number=tot3.loc[item]['Total_reads']\n",
    "        while counter1<number:\n",
    "            temp_tot[counter]=tot3.loc[item].values\n",
    "            counter+=1\n",
    "            counter1+=1\n",
    "    temp_tot2=pd.DataFrame.from_dict(temp_tot)\n",
    "    temp_tot2=temp_tot2.T\n",
    "    temp_tot2.columns=tot3.columns\n",
    "    return temp_tot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDict = {}\n",
    "#insert path to barcode text file\n",
    "with open('/../enriched_barcodes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        splitLine = line.split(',')\n",
    "        newDict[int(splitLine[0])] = splitLine[1][:-1]\n",
    "BC=setenv(newDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert path to non enriched deep sequencing molecule info H5 file from 10X pipeline\n",
    "c_path='/../molecule_info.h5'\n",
    "control=Read10x(c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CD_19, insert gene expression profile path\n",
    "#filtered_matrix_h5='/.../filtered_gene_bc_matrices_h5.h5'\n",
    "\n",
    "#HLA_DR, insert gene expression profile path\n",
    "filtered_matrix_h5='/../filtered_gene_bc_matrices_h5.h5'\n",
    "\n",
    "genome = \"hg19\"\n",
    "\n",
    "#load expression profile\n",
    "%time gene_bc_matrix = get_matrix_from_h5(filtered_matrix_h5, genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnames=gene_bc_matrix.gene_names\n",
    "cnames=gene_bc_matrix.barcodes\n",
    "DGE=pd.DataFrame(gene_bc_matrix.matrix.toarray())\n",
    "DGE.index=gnames\n",
    "DGE.columns=cnames\n",
    "cumi=DGE.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CD-19\n",
    "\n",
    "#list_a=[1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28]\n",
    "\n",
    "\n",
    "#HLA-DR\n",
    "\n",
    "list_a=[4,5,6,7,8,9]\n",
    "list_b=[12,13,14,15,16,17,30,31,32,33]\n",
    "list_c=[34,35,36,37,38,39,40,41,42,43]\n",
    "list_d=[44,45,46,47,48,49,50,51,52,53]\n",
    "list_e=[54,55,56,58,59,60,61,62,63,64,65,68]\n",
    "\n",
    "\n",
    "list_f=[4,5,6,7,8,9,12,13,14,15,16,17,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,48,49,50,51,52,53,54,55,56,58,59,60,61,62,63,64,65,68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert all barcodes to 2-bit encoded\n",
    "barcodes=defaultdict(str)\n",
    "for index, item in enumerate(cnames):\n",
    "        barcodes[index]=item[:-2]\n",
    "Tot_BC=setenv(barcodes)\n",
    "\n",
    "#reads per barcode for all barcodes\n",
    "reads=defaultdict(int)\n",
    "for k,v in Tot_BC.iteritems():\n",
    "    reads[v]=control[control.bc==v]['read_counts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples=[1,2,3] #replicate samples for one enrichment pool\n",
    "t_path=#path to data\n",
    "sample_path1='NR_'+str(samples[0])+'/'\n",
    "sample_path2='NR_'+str(samples[1])+'/'\n",
    "sample_path3='NR_'+str(samples[2])+'/'\n",
    "file_path='molecule_info.h5'\n",
    "NR1_=Read10x(t_path+sample_path1+file_path)\n",
    "NR2_=Read10x(t_path+sample_path2+file_path)\n",
    "NR3_=Read10x(t_path+sample_path3+file_path)\n",
    "NR1_['Sample']=1\n",
    "NR2_['Sample']=2\n",
    "NR3_['Sample']=3\n",
    "NR_tot=pd.concat([NR1_,NR2_,NR3_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_expanded_dataframe(NR_tot,list_a,BC,reads):    \n",
    "    t=NR_tot.copy()\n",
    "    t['bcumig']=zip(t.bc,t.umi,t.gene)\n",
    "    BCUMI_group=t.groupby('bcumig').sum()\n",
    "    BCUMI_group=pd.DataFrame(BCUMI_group[['unique','read_counts']])\n",
    "    BCUMI_group.columns=['Number','Total_reads']\n",
    "    BCUMI_group['BCUMIG']=BCUMI_group.index\n",
    "    Tot=BCUMI_group[['Number','Total_reads','BCUMIG']]\n",
    "\n",
    "    Tot['bc']=[x for x,y,z in Tot.BCUMIG]\n",
    "    Tot['umi']=[y for x,y,z in Tot.BCUMIG]\n",
    "    Tot['gene']=[z for x,y,z in Tot.BCUMIG]\n",
    "    \n",
    "\n",
    "    barcode=BC[item] \n",
    "    temp_sample1_1=Expanded_dataframe(Tot[Tot.bc==barcode])\n",
    "    return Tot,temp_sample1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias=defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in tqdm.tqdm_notebook(list_d,desc='0th loop'): \n",
    "    barcode=BC[item]\n",
    "    \n",
    "    boot=defaultdict()\n",
    "    Tot,temp_1=get_expanded_dataframe(NR_tot,item,BC,reads)\n",
    "    for i in tqdm.tqdm_notebook(range(10),desc='1st',leave=False):\n",
    "        temp=get_sample(Tot,reads,temp_1,barcode)\n",
    "        con_sample=control[control.bc==barcode]\n",
    "\n",
    "\n",
    "        control3=pd.DataFrame(control[['bc','umi','gene']])\n",
    "        control3['Enrich']='control'\n",
    "        sample3=pd.DataFrame(temp[['bc','umi','gene']])\n",
    "        sample3['Enrich']='enrich'\n",
    "        check2=pd.concat([control3[control3.bc!=barcode],sample3])\n",
    "        check3=check2[check2.gene!=32738]\n",
    "        check3['umig']=zip(check3.umi,check3.gene)\n",
    "        check3['val']=1\n",
    "        \n",
    "        BCUMI_group2=check3.groupby('umig').sum()\n",
    "        BCUMI_group2=pd.DataFrame(BCUMI_group2['val'])\n",
    "        BCUMI_group2.columns=['Number']\n",
    "        check4=check3.copy()\n",
    "        check4.index=check4['umig']\n",
    "        check4=check4.join(BCUMI_group2)\n",
    "        check5=check4[check4.Enrich=='enrich']\n",
    "        boot[i]=check5.Number.value_counts()\n",
    "    bias[item]=pd.DataFrame.from_dict(boot,orient='index').mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_df=pd.DataFrame.from_dict(bias,orient='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
